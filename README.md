# Mandarin to Taiwanese Southern Min Translation

## Environment Setup
- create conda environment using `env.yml`, which includes installing my personal fork of allennlp and allennlp-models:
    - `conda create env -f env.yml`
- You might need to pip uninstall -y dataclasses due to [this issue](https://github.com/allenai/allennlp/issues/4755) regarding installing Allennlp which Python version >= 3.7

## Data Setup
- at root directory of this repo, run:
```bash=
bash download_data.sh
```

## Training
```bash=
bash train.sh training_config/default.jsonnet <model_dir>
```

## Predict
```bash=
bash predict.sh /path/to/your/model.tar.gz <input_file> <output_file>
```
- `input_file`:  should be one line per sentence.
- `model.tar.gz`: generated by allennlp at the end of training. Pretrained model can be downloaded by running `bash download_model.sh`.
